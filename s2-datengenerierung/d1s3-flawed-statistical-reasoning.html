<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Tag 1: Der Daten-Lifecycle und: Woher kommen Daten?</title>
    <meta charset="utf-8" />
    <meta name="author" content="Simon Munzert" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css">
    <script src="https://tikzjax.com/v1/tikzjax.js"></script>
    <link rel="stylesheet" href="../simons-touch.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Tag 1: Der Daten-Lifecycle und: Woher kommen Daten?
]
.subtitle[
## Session 2: Datengenerierung und was dabei schief gehen kann
]
.author[
### Simon Munzert
]
.institute[
### Hertie School
]

---


&lt;style type="text/css"&gt;
@media print { # print out incremental slides; see https://stackoverflow.com/questions/56373198/get-xaringan-incremental-animations-to-print-to-pdf/56374619#56374619
  .has-continuation {
    display: block !important;
  }
}
&lt;/style&gt;






# Inhaltsverzeichnis

&lt;br&gt;&lt;br&gt;

1. [Schlechte Stichproben: Repräsentativität liegt im Auge des Betrachters](#sampling)

2. [Schlechte Analytik: Signifikanz ist nicht alles, was zählt](#analytics)

3. [Schlechte Schlussfolgerung: Korrelation impliziert keine Kausalität](#inference)

---
class: inverse, center, middle
name: correlation

# Schlechte Stichproben: Repräsentativität liegt im Auge des Betrachters
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px style="width:1000px; margin:auto;"/&gt;&lt;/html&gt;


---
# Getäuscht durch „Repräsentativität“

&lt;div align="center"&gt;
&lt;img src="../pics/survey-intelligence.png" height=450&gt;
&lt;/div&gt;

`Source` [Robin Andrews, IFLScience](https://www.iflscience.com/editors-blog/survey-finds-most-americans-think-that-they-have-above-average-intelligence/)


---
# Getäuscht durch „Repräsentativität“

&lt;div align="center"&gt;
&lt;img src="../pics/eu-summertime.png" height=400&gt;
&lt;/div&gt;

`Source` [Maxime Schlee, Politico](https://www.politico.eu/article/80-percent-of-eu-citizens-want-to-scrap-daylight-savings-report-summertime-directive/)




---
# Stichproben und Repräsentativität

.pull-left[
## Eine volkstümliche Definition von Repräsentativität

Eine Stichprobe (oder Daten im Allgemeinen) ist „repräsentativ“, wenn **die aus der Stichprobe gezogenen Schlüsse verallgemeinert werden können** für die Grundgesamtheit von Interesse.
]

.pull-right[
## Eine formalere Definition

Eine Stichprobe ist repräsentativ, wenn sie so gezogen wird, dass sie **statistisch nicht von der interessierenden Grundgesamtheit** unterscheidbar ist.
]

&lt;div align="center"&gt;
&lt;img src="../pics/samples.png" height=350&gt;
&lt;/div&gt;



---
# Das Problem mit dem Begriff „Repräsentativität“

## Warum „Repräsentativität“ ein problematischer Begriff ist

1. Ob eine Stichprobe repräsentativ ist, hängt von Ihrem Interesse ab.
2. Man kann eine Stichprobe nicht a priori als „repräsentativ“ bezeichnen. 
3. Die Beurteilung der Repräsentativität einer Stichprobe erfordert starke Annahmen über Ihr Wissen über die Grundgesamtheit und Ihre Messungen der Merkmale, die „repräsentativ“ sein sollten.

---
# Gesamtfehler der Umfrage

.pull-left[
## Inferenz in der Umfrageforschung

- Etwas über die Verteilung von Merkmalen in einer Grundgesamtheit erfahren
- Sammeln von Informationen aus einer Teilmenge der Grundgesamtheit

## Zwei Arten von Fehlern

- **Messfehler**: was man misst, ist nicht das, was man messen will
- Fehler der **Repräsentation**: Die Gruppe, die Sie beobachten, ist nicht verallgemeinerbar auf die interessierende Population
]

.pull-right[
## Gesamtfehler der Umfrage Framework

&lt;div align="center"&gt;
&lt;br&gt;
&lt;img src="../pics/total-survey-error.png" height=400&gt;
&lt;/div&gt;

`Source` [Groves et al. 2009, Survey Methodology](https://books.google.de/books?hl=de&amp;lr=&amp;id=HXoSpXvo3s4C)
]


---
# Mess- und Stichprobenfehler in freier Wildbahn

.pull-left[
## Überrepräsentation und falsche Angaben in Wahlumfragen

- Die Zahlen aus Umfragen nach der Wahl überschätzen die Wahlbeteiligung oft erheblich. 
- Zwei unterschiedliche Phänomene sind für diese Diskrepanz verantwortlich:
    1. Überrepräsentation der tatsächlichen Wähler
    2. Falsche Angaben zur Wahlbeteiligung durch Nichtwähler unter den Umfrageteilnehmern. 
- Studien zur Validierung der Wahlbeteiligung helfen, das Problem auf individueller Ebene zu identifizieren.
- Eine Verzerrung der Wahlbeteiligung kann sich auch auf Analysen nachgelagerter Variablen (z.B. Wahlverhalten) auswirken.
]

.pull-right[
&lt;div align="center"&gt;
&lt;br&gt;
&lt;img src="../pics/selb-munzert-overreporting.png" height=450&gt;
&lt;/div&gt;

`Source` [Selb and Munzert 2013, Electoral Studies](https://kops.uni-konstanz.de/server/api/core/bitstreams/e755783d-acee-4592-a666-1562fc912906/content)
]

---
# Schlechte Stichproben: gelernte Lektionen


.pull-left[
## Was bedeutet das für Sie?

- Nehmen Sie die angegebene „Repräsentativität“ nicht für bare Münze.
- Der Stichprobenumfang allein garantiert keine Repräsentativität.
- Lassen Sie sich nicht von „großen Datenmengen“ täuschen (sie sind standardmäßig nicht repräsentativ).
- Lassen Sie sich nicht von „Zufallsstichproben“ täuschen (sie sind standardmäßig nicht repräsentativ).
- Wahrscheinlichkeitsstichproben sind kein Allheilmittel, da Menschen immer noch eine Selbstselektion in/aus Stichproben vornehmen.
- Schlechte Stichproben sind nicht auf Erhebungen beschränkt (denken Sie z.B. an Daten aus sozialen Medien, die Auswahl von Fällen für eine medizinische Studie oder die Auswahl von Ländern für eine politische Studie).
]

.pull-right[
## Suchen Sie stattdessen nach den folgenden Punkten: 

1. **Transparenz** über das Stichprobenverfahren.
2. **Einschätzung** der Repräsentativität der Stichprobe.
3. **Validierung** der Stichprobe anhand externer Benchmarks.
4. **Gesunder Menschenverstand** (ist es sinnvoll, den Repräsentanten anzurufen?)
]


---
# Diskussion

.pull-left[

## Eckpunkte für die Diskussion

1. Zu welchem Zeitpunkt des Politikzyklus könnte welche Art der Konsultation sinnvoll sein?
2. Welche Vor- und Nachteile haben die verschiedenen Konsultationsarten für die Beobachtung und Bewertung?

&lt;div align="center"&gt;
&lt;img src="../pics/georgia-handbook-3.png" width=405&gt;
&lt;/div&gt;

`Source` Policy Planning, Monitoring and Evaluation Handbook, Government of Georgia
]

.pull-right[
&lt;div align="center"&gt;
&lt;img src="../pics/georgia-handbook-4.png" width=450&gt;
&lt;/div&gt;

`Source` Annex 11: Guideline for Public Consultations, Government of Georgia
]






---
class: inverse, center, middle
name: analytics

# Schlechte Analytik: Signifikanz ist nicht alles, was zählt
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px style="width:1000px; margin:auto;"/&gt;&lt;/html&gt;


---
# Zurück zu statistischer Signifikanz

.pull-left[
## Statistische Signifikanz in der Praxis
- Konventionell sollten Fehler vom Typ I um jeden Preis vermieden werden.
- Ein Ergebnis gilt als statistisch signifikant, wenn es sehr unwahrscheinlich ist, dass es unter einer wahren Nullhypothese aufgetreten wäre.
- Ein Signifikanzniveau `\(\alpha\)` gibt die Wahrscheinlichkeit eines Fehlers vom Typ I an. Üblicherweise wird es auf 5% festgelegt.
]

--

.pull-right[
## Gewisse Probleme
- Nur weil ein Effekt signifikant ist, heißt das nicht, dass er substanziell bedeutsam (groß) ist.
- Es gibt einen Anreiz für Forscher, statistisch signifikante Ergebnisse zu produzieren `\(\rightarrow\)` "publication bias"
- Statistische Signifikanz ist (auch) eine Funktion der Stichprobengröße. Es ist **trivial, mit großen Daten signifikante Ergebnisse zu erzielen**.
- Leider ist es auch oft **trivial, mit kleinen Daten signifikante Ergebnisse zu erzielen**, wenn man in Bezug auf seine Hypothesen flexibel ist.
]

---
# Lassen Sie sich nicht von übertriebenen Ausdrücken der Signifikanz täuschen.

&gt; „Die folgende Liste stammt aus begutachteten Zeitschriftenartikeln, in denen (a) die Autoren sich selbst den Schwellenwert von 0,05 für die Signifikanz gesetzt haben, (b) diesen Schwellenwert für p nicht erreicht haben und (c) ihn so beschrieben haben, dass er interessanter erscheint.“ [Matthew Hankins, Probable Error](https://goo.gl/iUGz7a)
&lt;br&gt;

&gt; *(knapp) nicht statistisch signifikant (p=0,052), ein kaum nachweisbarer statistisch signifikanter Unterschied (p=0,073), ein grenzwertig signifikanter Trend (p=0,09), ein gewisser Trend zur Signifikanz (p=0,08), eine klare Tendenz zur Signifikanz (p=0,052), ein klarer Trend (p&lt;0. 09), ein klarer, starker Trend (p=0,09), ..., sehr knapp an der Grenze der statistischen Signifikanz (p=0,051), sehr knapp an der Signifikanz vorbei (p&lt;0,06), sehr knapp signifikant (p=0,0656), sehr knapp nicht signifikant (p=0,10), sehr knapp signifikant (p&lt;0,1), 
praktisch signifikant (p=0,059), schwach signifikant (p&gt;0,10), abgeschwächt signifikant (p=0,06), schwach nicht signifikant (p=0,07), schwach signifikant (p=0,11), schwach statistisch signifikant (p=0,0557), nahezu signifikant (p=0,11)*

---
# Daten-Fishing und p-Hacking

.pull-left-wide2[
## Das Problem

Die Dominanz der statistischen Signifikanz als Entscheidungskriterium bei wissenschaftlichen Veröffentlichungen macht die p-Werte zu einem wichtigen Zielkriterium bei der statistischen Analyse. Kleine p-Werte werden häufiger berichtet, als man erwarten würde!

## Die Symptome

- **Daten-Fishing**: Testen vieler Hypothesen bis zur Signifikanz
- **p-Hacking**: Optimieren der Analyse (z.B. Hinzufügen/Entfernen von Kontrollen, Transformieren von Variablen, Ändern von Modellen) bis zur Signifikanz
- **HARKing**: **H**ypothesizing **a**fter the **r**esults are **k**nown (Hypothesenbildung nachdem die Ergebnisse bekannt sind) 
## Das Gegenmittel?

Sonderausgabe in [The American Statistician, 2019](https://www.tandfonline.com/toc/utas20/73/sup1): *"Statistical Inference in the 21st Century: A World Beyond p &lt; 0.05"*
]

.pull-right-small2[
&lt;div align="center"&gt;
&lt;div class=font50&gt;&lt;b&gt;Figure:&lt;/b&gt; Distribution of reported p-values (within [.001–.15]).&lt;/div&gt;
&lt;img src="../pics/p-values-pone.png" height=260&gt;&lt;br&gt;
&lt;/div&gt;

&gt; "Der Datensatz besteht aus über 135'000 Datensätzen. Die Daten wurden mittels computergestützter Suche aus (...) fünf Journals of Experimental Psychology im Zeitraum von Januar 1996 bis März 2008 gewonnen." 

`Source` [Krawczyk, M., 2015, PLOS ONE](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0127872)
]


---
# Daten-Fishing and p-Hacking: Übung

.pull-left[
## Übung
- Schau dir [https://projects.fivethirtyeight.com/p-hacking/](https://projects.fivethirtyeight.com/p-hacking/) an.
- Verbringen Sie fünf Minuten damit, sich zu wissenschaftlichem Ruhm zu hacken
- Mehr Hintergrundinformationen [hier](https://fivethirtyeight.com/features/science-isnt-broken).

]

.pull-right[
&lt;br&gt;
&lt;div align="center"&gt;
&lt;img src="../pics/fivethirtyeight-hacking.png" height=400&gt;
&lt;/div&gt;
]


---
# Die Folgen der Vorregistrierung

.pull-left[
## Die Idee
- Vorregistrierung bedeutet, dass Sie Ihre Studie (Hypothesen, Methoden, Analysen) registrieren (z.B. indem Sie sie online stellen), bevor sie durchgeführt wird
- In den letzten Jahren hat sich die Forschungspraxis stark verändert; siehe das [Open Science Framework (OSF) Registry](https://osf.io/registries/osf/new) und das [American Economic Association (AEA) RCT Registry](https://docs.socialscienceregistry.org/)
## Warum das wichtig ist

&gt; "17 von 30 Studien (57\%), die vor dem Jahr 2000 veröffentlicht wurden, zeigten einen signifikanten Nutzen der Intervention für das primäre Ergebnis im Vergleich zu nur 2 der 25 (8\%) Studien, die nach 2000 veröffentlicht wurden." (siehe Grafik)
]

.pull-right-center[
&lt;div class=font50&gt;&lt;b&gt;Figure:&lt;/b&gt; Relatives Risiko, einen Nutzen oder Schaden der Behandlung zu zeigen, nach Jahr der Veröffentlichung für große NHLBI-Studien zu Arzneimitteln und Nahrungsergänzungsmitteln.&lt;/div&gt;&lt;br&gt;

&lt;div align="center"&gt;
&lt;img src="../pics/preregistration-effect.jpg" height=400&gt;
&lt;/div&gt;

`Source` [Kaplan et al. 2015; PLOS ONE](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0132382)
]


---
# Teststärke (statistical power)
.pull-left[
## Das Konzept
- Wir sind daran gewöhnt, uns vor falsch-positiven Ergebnissen (Signifikanztests!) zu schützen, aber auch falsch-negative Ergebnisse können schaden - insb., wenn die Durchführung einer Studie sehr kostspielig war
- Die statistische Aussagekraft ist die **Wahrscheinlichkeit, die Nullhypothese korrekt zurückzuweisen, wenn sie falsch ist**.
- Die Fähigkeit, Signal und Rauschen zu unterscheiden, wobei das Signal der interessierende Behandlungseffekt ist
- P(„Es gibt einen Effekt und ich sehe ihn“): Aussagekraft = 1 - Fehler vom Typ II
- Je höher die statistische Aussagekraft eines Experiments ist, desto geringer ist die Wahrscheinlichkeit eines Fehlers vom Typ II.
]

.pull-right[
&lt;br&gt;
&lt;div align="center"&gt;
&lt;img src="../pics/stat_power_base.png" height=400&gt;
&lt;/div&gt;
]

---
# Teststärke (statistical power)

.pull-left-wide2[
## Motivation
- Ist Ihre Stichprobe groß genug, um einen Effekt einer bestimmten Größe aufzudecken? Führen Sie eine Power-Analyse durch (idealerweise vor der Datenerhebung)!
- Bei der [Power-Analyse](https://egap.org/resource/10-things-to-know-about-statistical-power/) wird die Wahrscheinlichkeit ermittelt, mit der ein Effekt einer bestimmten Größe bei einem bestimmten Stichprobenumfang entdeckt wird.
- Wenn Sie es sich leisten können, passen Sie den Stichprobenumfang und/oder das Design auf der Grundlage Ihrer Power-Berechnungen an

## Berechnung
- Mehrere Teststärke-Formeln für verschiedene Versuchs- (und Beobachtungs-) Designs
- Die Formeln können umgestellt werden, um z.B. `\(N\)` zu bestimmen.
- Es gibt viele handelsübliche Potenzrechner, z. B. [hier](https://egap.shinyapps.io/power-app/) (Erläuterung [hier](https://www.povertyactionlab.org/sites/default/files/research-resources/ExerciseC_PowerCalc_Participants.pdf))
- In der Praxis erfordert die Durchführung von Teststärke-Analysen mehr oder weniger starke Annahmen über die Effektgröße 
]

.pull-right-small2[
## Formeln

Teststärkeberechnung für zwei Gruppen Differenz-im-Mittelwert-Test mit gleichen Varianzen und Gruppengrößen:

`\(\text{power} = \Phi(\frac{|\mu_{t}-\mu_{c}|\sqrt{N}}{2\sigma}-\Phi^{-1}(1-\frac{\alpha}{2}))\)`

- `\(\Phi\)` ist die CDF der Normalverteilung `\(\rightarrow\)` Teststärke unter der Annahme, dass sie der Normalverteilung folgt
- `\(\mu_{t,c}\)` ist das durchschnittliche Ergebnis in der Behandlungs-/Kontrollgruppe `\(\rightarrow\)` Effekt
- `\(\sigma\)` ist die Standardabweichung der Ergebnisse `\(\rightarrow\)` Störanfälligkeit
- `\(\alpha\)` ist das gewählte Signifikanzniveau, häufig 0,05 nach Konvention
- `\(N\)` ist die Gesamtzahl der Probanden
]

---
# Teststärke Analyse: Beispiel

.pull-left[
## Beispiel
- Sie möchten einen Anstieg der Wahlbeteiligung um 5 % aufgrund einer neuen Kampagne feststellen
- Sie haben eine Stichprobe von 500 Wählern
- Gehen Sie von einer Standardabweichung der Wahlbeteiligung von 20% aus.
- Nehmen Sie ein Signifikanzniveau von 0,05 an.
- Wie hoch ist die Aussagekraft Ihrer Studie?
- Verwenden Sie z.B. [EGAP-Rechner](https://egap.shinyapps.io/power-app/)

## Berechnung
- `\(\mu_{t}-\mu_{c} = 0.05\)`
- `\(\sigma = 0.2\)`
- `\(N = 500\)`
- `\(\alpha = 0.05\)`
- Power = ?
]

.pull-right[
## Probability density function (PDF) vs. Cumulative density function (CDF)
&lt;br&gt;
&lt;div align="center"&gt;
&lt;img src="../pics/pdf_cdf.jpg" height=380&gt;
&lt;/div&gt;
]







---
# Schlechte Analytik: gelernte Lektionen

.pull-left-wide[
## Checkliste

- **Prüfen Sie die Evidenz.** Ist sie wirklich statistisch signifikant?
- **Betrachten Sie die Theorie und die Evidenz.** Ist sie plausibel?
- **Schauen Sie sich das Design an.** Können Sie irgendwelche größeren Fehler entdecken?
- **Betrachten Sie die Effektgröße.** Ist sie aussagekräftig? Ist sie zu gut, um wahr zu sein?
- **Schauen Sie sich die Stichprobengröße an.** Ist sie angemessen groß? Ist die Studie gut getestet?
- **Prüfen Sie, ob die Studie vorregistriert wurde.** Erkennen Sie Ad-hoc-Hypothesen.
- **Vertrauen Sie keiner einzelnen Studie.** Achten Sie auf Meta-Analysen!
]

.pull-right-small[
&lt;br&gt;
&lt;div align="center"&gt;
&lt;img src="../pics/checklist.jpeg" height=300&gt;
&lt;/div&gt;
]




---

class: inverse, center, middle
name: inference

# Schlechte Inferenz: Korrelation impliziert keine Kausalität
&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px style="width:1000px; margin:auto;"/&gt;&lt;/html&gt;

---
# Ein Klassiker

&lt;div align="center"&gt;
&lt;br&gt;
&lt;img src="../pics/correlation-xkcd.png" height=350&gt;
&lt;/div&gt;

`Source` [XKCD 552](https://xkcd.com/552/)


---
class: exercise, center

# Übung

&lt;br&gt;&lt;br&gt;

# Raten Sie die Korrelationen!

&lt;div align="center"&gt;
&lt;img src="../pics/cor-examples1.png" height=400&gt;
&lt;/div&gt;


---
class: exercise, center

# Übung

&lt;br&gt;&lt;br&gt;

# Raten Sie die Korrelationen!

&lt;div align="center"&gt;
&lt;img src="../pics/cor-examples2.png" height=400&gt;
&lt;/div&gt;


---
class: exercise, center

# Übung

&lt;br&gt;&lt;br&gt;

# Raten Sie die Korrelationen!

&lt;div align="center"&gt;
&lt;img src="../pics/cor-examples3.png" height=400&gt;
&lt;/div&gt;

---
class: exercise, center

# Übung

&lt;br&gt;&lt;br&gt;

# Raten Sie die Korrelationen!

&lt;div align="center"&gt;
&lt;img src="../pics/cor-examples4.png" height=400&gt;
&lt;/div&gt;

---
class: exercise, center

# Übung

&lt;br&gt;&lt;br&gt;

# Raten Sie die Korrelationen!

&lt;div align="center"&gt;
&lt;img src="../pics/cor-examples5.png" height=400&gt;
&lt;/div&gt;

---
class: exercise, center

# Übung

&lt;br&gt;&lt;br&gt;

# Raten Sie die Korrelationen!

&lt;div align="center"&gt;
&lt;img src="../pics/cor-examples6.png" height=400&gt;
&lt;/div&gt;


---
class: exercise, center

# Übung

&lt;br&gt;&lt;br&gt;

# Raten Sie die Korrelationen!

&lt;div align="center"&gt;
&lt;img src="../pics/cor-examples7.png" height=400&gt;
&lt;/div&gt;

---
# Korrelationen besser erraten

## Siehe http://guessthecorrelation.com/

&lt;br&gt;
&lt;div align="center"&gt;
&lt;img src="../pics/guess-the-correlation-1.png" height=350&gt;
&lt;img src="../pics/guess-the-correlation-2.png" height=350&gt;
&lt;/div&gt;


---
# Die Mathematik der Korrelation, erklärt

.pull-left[
## Der Pearson-Korrelationskoeffizient

- Misst die **Stärke und Richtung** einer **linearen Beziehung** zwischen zwei Variablen
- Der Bereich reicht von -1 bis 1
- Formel zur Berechnung:
`\(r_{xy} = \frac{\text{covariation of X and Y}}{\text{separate variation of X and Y}} = \frac{Cov(x, y)}{s_x s_y} = \sum_i \frac{(x_i - \bar{x})(y_i - \bar{y})}{s_x s_y}\)`
 ]
 

.pull-right[
## Pearson's r ist...
- positiv, wenn die Variablen A und B gemeinsam steigen
- negativ, wenn A[B] steigt und B[A] sinkt
- 1, wenn A und B gemeinsam steigen
-1, wenn A steigt und B sinkt
- 0, wenn A und B nicht kovariieren
]

&lt;div align="center"&gt;
&lt;img src="../pics/cor-examples7.png" height=260&gt;
&lt;/div&gt;




---
# Korrelation bedeutet nicht gleich Kausalität

.pull-left[
## Korrelation

Zwei Variablen sind **korreliert**, wenn die Kenntnis des Wertes der einen Variablen Aufschluss über den wahrscheinlichen Wert der anderen gibt.

## Kausalität

Zwei Ereignisse sind **kausal miteinander verbunden**, wenn das Auftreten des einen Ereignisses eine Folge des Auftretens des anderen ist.

## Der kausale Trugschluss

Zwei Variablen, die miteinander korreliert sind, stehen nicht notwendigerweise in einer Ursache-Wirkungs-Beziehung.

- cum hoc ergo propter hoc („damit, also deswegen“)
- post hoc ergo propter hoc („nach diesem, also wegen diesem“)
]

.pull-right[

]



---
# Scheinkorrelationen

&lt;div align="center"&gt;
&lt;img src="../pics/2563_american-cheese-consumption_correlates-with_total-geothermal-power-generated-globally.png" height=450&gt;
&lt;/div&gt;

`Source` [Tyler Vigen, http://tylervigen.com/spurious-correlations](http://tylervigen.com/spurious-correlations)

---
# Scheinkorrelationen

&lt;div align="center"&gt;
&lt;img src="../pics/5236_number-of-websites-on-the-internet_correlates-with_total-wind-power-generated-globally.png" height=450&gt;
&lt;/div&gt;

`Source` [Tyler Vigen, http://tylervigen.com/spurious-correlations](http://tylervigen.com/spurious-correlations)


---
# Scheinkorrelationen

&lt;div align="center"&gt;
&lt;img src="../pics/7776_google-searches-for-barack-obama_correlates-with_kerosene-used-in-jamaica.png" height=450&gt;
&lt;/div&gt;

`Source` [Tyler Vigen, http://tylervigen.com/spurious-correlations](http://tylervigen.com/spurious-correlations)


---
# Was bedeutet es also, wenn die Variablen A und B korreliert sind?
## Einige mögliche Erklärungen

- A verursacht B (direkte Kausalität)
- B verursacht A (umgekehrte Kausalität)
- A und B sind Folgen einer gemeinsamen Ursache (Confounding)
- A verursacht C, das B verursacht (Mediation)
- A und B verursachen beide C, das bedingt wird (collider bias)
- Es gibt keinen Zusammenhang zwischen A und B, die empirische Korrelation ist ein Zufall (Scheinkorelation)

## Wie kann man zwischen diesen unterscheiden?

- **Experimentelle Designs** (randomisierte kontrollierte Studien)
- **Natürliche Experimente** (Quasi-Experimente)
- **Observationsdaten** (sorgfältige Analyse von Störfaktoren und Kollisionen)
- **Gesunder Menschenverstand** (ist es sinnvoll, dass A Ursache für B ist?)
- **Rivalisierende Erklärungen** (können wir andere Erklärungen ausschließen?)



---
# Schlechte Inferenz: gelernte Lektionen

.pull-left[
## Was bedeutet das für Sie?

- Lassen Sie sich nicht von **hoher Korrelation oder großer Effektgröße** täuschen.
- Lassen Sie sich nicht von der **statistischen Signifikanz** täuschen.
- Lassen Sie sich nicht von **großer erklärter Varianz (R-Quadrat)** täuschen. 
]

.pull-right[
## Stellen Sie sich stattdessen die folgenden Fragen:

1. Ist es wirklich sinnvoll, dass A Ursache für B ist?
2. Gibt es Beweise, die andere Erklärungen ausschließen?
3. Stützen sich die Beweise auf einen sauberen Versuchsplan?
4. Beruhen die Beweise auf einem natürlichen Experiment mit einer überzeugenden Geschichte?
5. Wenn es keine (Quasi-)Experimente gibt, beruht der Nachweis auf einer sorgfältigen Analyse von Beobachtungsdaten, wobei plausible Störfaktoren und Kollider berücksichtigt werden?
]






    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"hash": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
  .logo {
    background-image: url("../hertieschool-neg.svg");
    background-size: contain;
    background-repeat: no-repeat;
    position: absolute;
    top: 1.5em;
    right: 1em;
    width: 150px;
    height: 128px;
    z-index: 0;
  }
</style>
  
  <script>
  document
.querySelectorAll(
  '.remark-slide-content' +
    ':not(.title-slide)' +
    ':not(.inverse)' +
	
    // add additional classes to exclude here, e.g.
  // ':not(.inverse)' +
    ':not(.hide-logo)'
)
.forEach(el => {
  el.innerHTML += '<div class="logo"></div>';
});
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
